langchain
langchain-community
langchain-core
langchain-text-splitters
faiss-cpu
sentence-transformers
flask
langchain-huggingface
requests
beautifulsoup4
torch
transformers
accelerate
huggingface_hub
# Speed optimization libraries
optimum>=1.16.0
# Flash attention requires compilation - install separately if needed
# flash-attn is optional but provides 3-4x speedup if compiled successfully
packaging  # Required by flash-attn and other packages
ninja  # Build tool for flash-attn compilation
